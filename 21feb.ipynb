{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7522f-967d-4c79-91b9-521332d86012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Web scraping is the process of extracting data from websites automatically using specialized software or programming tools. It involves analyzing the HTML structure of a webpage and extracting specific information based on patterns and rules.\n",
    "\n",
    "Web scraping is used to automate data collection and analysis tasks that would otherwise be tedious and time-consuming. It allows organizations and individuals to gather large amounts of data from the internet quickly and efficiently.\n",
    "\n",
    "Here are three areas where web scraping is commonly used to get data:\n",
    "\n",
    "Market Research: Companies use web scraping to gather data on their competitors, such as product prices, customer reviews, and market trends.\n",
    "\n",
    "Academic Research: Researchers use web scraping to collect data for academic studies, such as sentiment analysis of social media or online forums, and to gather data on social, economic, and political trends.\n",
    "\n",
    "Lead Generation: Businesses use web scraping to collect contact information from websites, such as email addresses and phone numbers, to generate leads and build customer databases.\n",
    "\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "1.Using web scraping libraries: There are many web scraping libraries available for programming languages like Python, such as BeautifulSoup, Scrapy, and Requests. These libraries allow developers to extract data from websites by writing code that interacts with the HTML structure of the page.\n",
    "\n",
    "2.Parsing HTML: HTML pages can be parsed using regular expressions or other methods to extract specific data. This method requires knowledge of HTML syntax and may be less reliable than using a web scraping library.\n",
    "\n",
    "3.Automated tools: There are many automated web scraping tools available that allow users to extract data from websites without writing any code. These tools typically use machine learning algorithms to identify data patterns and extract the relevant information.\n",
    "\n",
    "4.Browser extensions: Some browser extensions, such as Web Scraper and Data Miner, allow users to extract data from websites by selecting the data they want and exporting it in various formats.\n",
    "\n",
    "5.API: Some websites offer an Application Programming Interface (API) that allows developers to access specific data in a structured format. This method is often faster and more reliable than web scraping, but it requires access to the website's API and may be limited to specific types of data.\n",
    "\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "Beautiful Soup is a Python library used for web scraping purposes to extract data from HTML and XML files. It is a popular choice for web scraping because it is user-friendly, easy to learn, and provides powerful methods for parsing and manipulating HTML data.\n",
    "\n",
    "Beautiful Soup allows users to search, navigate, and modify the parse tree of an HTML or XML document. It can handle poorly-formed HTML code and can be used to extract specific tags, attributes, and data from web pages.\n",
    "\n",
    "Some of the reasons why Beautiful Soup is widely used are: 1>Easy to use 2>Powerful Parsing 3>Versatile 4>Supports multiple data formats\n",
    "\n",
    "Q4. Why is flask used in this Web Scraping project?\n",
    "Here are some of the reasons why Flask is a good choice for this kind of project:\n",
    "\n",
    "1>Lightweight: Flask is a lightweight web framework that is easy to set up and does not require much overhead, making it a good choice for small to medium-sized web scraping projects.\n",
    "\n",
    "2>Easy to learn: Flask has a simple and intuitive interface, making it easy to learn for beginners who are new to web development.\n",
    "\n",
    "3>Flexible: Flask provides a lot of flexibility in terms of how web applications can be built, allowing developers to customize their applications according to their needs.\n",
    "\n",
    "4>Easy integration with web scraping libraries: Flask can be easily integrated with popular web scraping libraries like BeautifulSoup and Scrapy, making it easy to run web scraping scripts and display the results in a web interface.\n",
    "\n",
    "5>Supports various data formats: Flask can handle various data formats, such as JSON and CSV, making it easy to display scraped data in a user-friendly way.\n",
    "\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "AWS Elastic Beanstalk: It is a fully-managed service that provides a platform for deploying and scaling web applications. In this project, Elastic Beanstalk is used to deploy and run the Flask web application.\n",
    "\n",
    "AWS Lambda: It is a serverless computing service that allows running code in response to events or triggers without the need for provisioning or managing servers. In this project, Lambda is used to run the web scraping script on a scheduled basis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
